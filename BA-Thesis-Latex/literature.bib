




@article{Dorr2017,
	title        = {Towards Applying the OPRA Theory to Shape Similarity},
	author       = {Dorr, Christopher H. and Moratz, Reinhard},
	year         = 2017,
	number       = {May 2017},
	url          = {http://arxiv.org/abs/1705.02653},
	abstract     = {The motivation for using qualitative shape descriptions is as follows: qualitative shape descriptions can implicitly act as a schema for measuring the similarity of shapes, which has the potential to be cognitively adequate. Then, shapes which are similar to each other would also be similar for a pattern recognition algorithm. There is substantial work in pattern recognition and computer vision dealing with shape similarity. Here with our approach to qualitative shape descriptions and shape similarity, the focus is on achieving a representation using only simple predicates that a human could even apply without computer support.},
	archiveprefix = {arXiv},
	arxivid      = {1705.02653},
	eprint       = {1705.02653},
	file         = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/Towards_Applying_the_OPRA_Theory_to_Shape_Similari.pdf:pdf},
	mendeley-groups = {Proposal,Proposal/Small}
}
@incollection{Barkowsky2000,
	title        = {Schematizing Maps: Simplification of Geographic Shape by Discrete Curve Evolution},
	author       = {Barkowsky, Thomas and Latecki, Longin Jan and Richter, Kai -Florian},
	year         = 2000,
	volume       = 8,
	pages        = {41--53},
	doi          = {10.1007/3-540-45460-8\_4},
	url          = {http://link.springer.com/10.1007/3-540-45460-8\_4},
	abstract     = {Shape simplification in map-like representations is used for two reasons: either to abstract from irrelevant detail to reduce a map user's cognitive load, or to simplify information when a map of a smaller scale is derived from a detailed reference map. We present a method for abstracting simplified cartographic representations from more accurate spatial data. First, the employed method of discrete curve evolution developed for simplifying perceptual shape characteristics is explained. Specific problems of applying the method to cartographic data are elaborated. An algorithm is presented, which on the one hand simplifies spatial data up to a degree of abstraction intended by the user; and which on the other hand does not violate local spatial ordering between (elements of) cartographic entities, since local arrangement of entities is assumed to be an important spatial knowledge characteristic. The operation of the implemented method is demonstrated using two different examples of cartographic data.},
	file         = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester\_SS\_2023/BA Vorbereitung/Moratz\_Thema/Literatur/Schematizing\_Maps\_Simplification\_of\_Geog.pdf:pdf},
	mendeley-groups = {Proposal,Proposal/Small}
}
@article{Latecki1999d,
	title        = {Convexity Rule for Shape Decomposition Based on Discrete Contour Evolution},
	author       = {Latecki, Longin Jan and Lak{\"{a}}mper, Rolf},
	year         = 1999,
	journal      = {Computer Vision and Image Understanding},
	volume       = 73,
	number       = 3,
	pages        = {441--454},
	doi          = {10.1006/cviu.1998.0738},
	issn         = 10773142,
	abstract     = {We concentrate here on decomposition of 2D objects into meaningfulparts of visual form, orvisual parts. It is a simple observation that convex parts of objects determine visual parts. However, the problem is that many significant visual parts are not convex, since a visual part may have concavities. We solve this problem by identifying convex parts at different stages of a proposed contour evolution method in which significant visual parts will become convex object parts at higher stages of the evolution. We obtain a novel rule for decomposition of 2D objects into visual parts, called the hierarchical convexity rule, which states that visual parts are enclosed by maximal convex (with respect to the object) boundary arcs at different stages of the contour evolution. This rule determines not only parts of boundary curves but directly the visual parts of objects. Moreover, the stages of the evolution hierarchy induce a hierarchical structure of the visual parts. The more advanced the stage of contour evolution, the more significant is the shape contribution of the obtained visual parts. {\textcopyright} 1999 Academic Press.},
	file         = {:C\:/Users/timol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Latecki, Lak{\"{a}}mper - 1999 - Convexity Rule for Shape Decomposition Based on Discrete Contour Evolution.pdf:pdf},
	keywords     = {Digital curves,Digital geometry,Digital straight line segments,Discrete curve evolution,Shape hierarchy,Total curvature,Visual parts},
	mendeley-groups = {Proposal,Proposal/Small}
}

@article{Latecki1999a,
abstract = {We concentrate here on decomposition of 2D objects into meaningfulparts of visual form, orvisual parts. It is a simple observation that convex parts of objects determine visual parts. However, the problem is that many significant visual parts are not convex, since a visual part may have concavities. We solve this problem by identifying convex parts at different stages of a proposed contour evolution method in which significant visual parts will become convex object parts at higher stages of the evolution. We obtain a novel rule for decomposition of 2D objects into visual parts, called the hierarchical convexity rule, which states that visual parts are enclosed by maximal convex (with respect to the object) boundary arcs at different stages of the contour evolution. This rule determines not only parts of boundary curves but directly the visual parts of objects. Moreover, the stages of the evolution hierarchy induce a hierarchical structure of the visual parts. The more advanced the stage of contour evolution, the more significant is the shape contribution of the obtained visual parts. {\textcopyright} 1999 Academic Press.},
author = {Latecki, Longin Jan and Lak{\"{a}}mper, Rolf},
doi = {10.1006/cviu.1998.0738},
file = {:C\:/Users/timol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Latecki, Lak{\"{a}}mper - 1999 - Convexity Rule for Shape Decomposition Based on Discrete Contour Evolution.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Digital curves,Digital geometry,Digital straight line segments,Discrete curve evolution,Shape hierarchy,Total curvature,Visual parts},
mendeley-groups = {Proposal,Proposal/Small,BA Thesis},
number = {3},
pages = {441--454},
title = {{Convexity Rule for Shape Decomposition Based on Discrete Contour Evolution}},
volume = {73},
year = {1999}
}

@article{Latecki1999c,
abstract = {We propose a simple approach to evolution of polygonal curves that is specially designed to fit discrete nature of curves in digital images. It leads to simplification of shape complexity with no blurring (i.e., shape rounding) effects and no dislocation of relevant features. Moreover, in our approach the problem to determine the size of discrete steps for numerical implementations does not occur, since our evolution method leads in a natural way to a finite number of discrete evolution steps which are just the iterations of a basic procedure of vertex deletion.},
author = {Latecki, Longin Jan and Lak{\"{a}}mper, Rolf},
doi = {10.1007/3-540-48236-9_35},
file = {:C\:/Users/timol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Latecki, Lak{\"{a}}mper - 1999 - Polygon evolution by vertex deletion.pdf:pdf},
isbn = {354066498X},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Discrete curve evolution,Shape recognition,Shape simplification},
mendeley-groups = {Proposal,BA Thesis},
pages = {398--409},
title = {{Polygon evolution by vertex deletion}},
volume = {1682},
year = {1999}
}

@article{Nehring2021,
author = {Nehring, Claudia and Gaiser, Carmen},
journal = {Verband Unbemannte Luftfahrt (VUL): Drone Industry Insights},
mendeley-groups = {Proposal,Proposal/Small},
pages = {23},
title = {{Analyse des deutschen Drohnenmarktes}},
url = {https://www.bdl.aero/de/publikation/analyse-des-deutschen-drohnenmarktes/  https://www.bdli.de/sites/default/files/global\_upload\_upload/Analyse des deutschen Drohnenmarktes.pdf},
year = {2021}
}

@misc{futuretrends2017,
author ={o. A.},
booktitle = {futuretrends.ch},
mendeley-groups = {Proposal/Small},
title = {{Trend: Die Geschichte der Kamera Drohnen}},
url = {https://www.futuretrends.ch/blog/trend-die-geschichte-der-kamera-drohnen/},
urldate = {2023-04-28},
year = {2017}
}


@article{Otsu1979,
abstract = {A nonparametric and unsupervised method of automatic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zeroth- and the first-order cumulative moments of the gray-level histogram. It is straightforward to extend the method to multithreshold problems. Several experimental results are also presented to support the validity of the method.},
author = {Otsu, Nobuyuki and Smith, P L and Reid, D B and Environment, Cluttered and Palo, Lockheed and Alto, Palo and Smith, P L},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester\_SS\_2023/BA Vorbereitung/Moratz\_Thema/Literatur/A\_Threshold\_Selection\_Method\_from\_Gray-Level\_Histograms.pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
mendeley-groups = {Proposal/Small},
number = {1},
pages = {62--66},
title = {{A Threshold Selection Method from Gray-Level Histogram}},
volume = {C},
year = {1979}
}
@article{Plastiras2018,
abstract = {Many applications utilizing Unmanned Aerial Vehicles (UAVs) require the use of computer vision algorithms to analyze the information captured from their on-board camera. Recent advances in deep learning have made it possible to use single-shot Convolutional Neural Network (CNN) detection algorithms that process the input image to detect various objects of interest. To keep the computational demands low these neural networks typically operate on small image sizes which, however, makes it difficult to detect small objects. This is further emphasized when considering UAVs equipped with cameras where due to the viewing range, objects tend to appear relatively small. This paper therefore, explores the trade-offs involved when maintaining the resolution of the objects of interest by extracting smaller patches (tiles) from the larger input image and processing them using a neural network. Specifically, we introduce an attention mechanism to focus on detecting objects only in some of the tiles and a memory mechanism to keep track of information for tiles that are not processed. Through the analysis of different methods and experiments we show that by carefully selecting which tiles to process we can considerably improve the detection accuracy while maintaining comparable performance to CNNs that resize and process a single image which makes the proposed approach suitable for UAV applications.},
archivePrefix = {arXiv},
arxivId = {1911.06073},
author = {Plastiras, George and Kyrkou, Christos and Theocharides, Theocharis},
doi = {10.1145/3243394.3243692},
eprint = {1911.06073},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/unkategorisiert/YOLO Algorithm Paper.pdf:pdf},
isbn = {9781450365116},
journal = {ACM International Conference Proceeding Series},
keywords = {Aerial cameras,Convolutional neural networks,Object detection,Pedestrian detection},
mendeley-groups = {Proposal/Small},
title = {{Efficient convnet-based object detection for unmanned aerial vehicles by selective tile processing}},
year = {2018}
}

@misc{Metz2022,
author = {Metz, Joseph},
mendeley-groups = {Proposal/Small},
title = {{Rechtslage: Drohnen an Autobahnen}},
url = {https://www.youtube.com/watch?v=oOw6nVnMbYo},
urldate = {2023-05-15},
year = {2022}
}



@article{Millman2011,
abstract = {Python has arguably become the de facto standard for exploratory, interactive, and computation-driven scientific research. This issue discusses Python's advantages for scientific research and presents several of the core Python libraries and tools used in scientific research. {\textcopyright} 2011 IEEE.},
author = {Millman, K. Jarrod and Aivazis, Michael},
doi = {10.1109/MCSE.2011.36},
file = {:C\:/Users/timol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Millman, Aivazis - 2011 - Python for scientists and engineers.pdf:pdf},
issn = {15219615},
journal = {Computing in Science and Engineering},
keywords = {Programming languages,Python,Python libraries,Python tools,Scientific computing,interactive research},
mendeley-groups = {BA Thesis},
month = {mar},
number = {2},
pages = {9--12},
title = {{Python for scientists and engineers}},
volume = {13},
year = {2011}
}

@article{Matsugu2003,
abstract = {Reliable detection of ordinary facial expressions (e.g. smile) despite the variability among individuals as well as face appearance is an important step toward the realization of perceptual user interface with autonomous perception of persons. We describe a rule-based algorithm for robust facial expression recognition combined with robust face detection using a convolutional neural network. In this study, we address the problem of subject independence as well as translation, rotation, and scale invariance in the recognition of facial expression. The result shows reliable detection of smiles with recognition rate of 97.6 Percent for 5600 still images of more than 10 subjects. The proposed algorithm demonstrated the ability to discriminate smiling from talking based on the saliency score obtained from voting visual cues. To the best of our knowledge, it is the first facial expression recognition model with the property of subject independence combined with robustness to variability in facial appearance. {\textcopyright} 2003 Elsevier Science Ltd. All rights reserved.},
author = {Matsugu, Masakazu and Mori, Katsuhiko and Mitari, Yusuke and Kaneda, Yuji},
doi = {10.1016/S0893-6080(03)00115-1},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/YOLO/Vorbemerkungen/Subject-independent-facial-expression-recognition-with-robust-_2003_Neural-N.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Convolutional neural network,Face detection,Facial expression},
mendeley-groups = {BA Thesis},
number = {5-6},
pages = {555--559},
pmid = {12850007},
title = {{Subject independent facial expression recognition with robust face detection using a convolutional neural network}},
volume = {16},
year = {2003}
}


@article{OSheaRyan2022,
abstract = {Abstract: The field of machine learning has taken a dramatic twist in re- cent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models can far exceed the per- performance of previous forms of artificial intelligence in common machine-learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offer a simplified method of getting started with ANNs. This document briefly introduces CNNs, discussing recently published papers and newly formed techniques in developing this bill- leniently fantastic image recognition models. This introduction assumes you are familiar with ANNs and machine learning fundamentals.},
archivePrefix = {arXiv},
arxivId = {1511.08458},
author = {O'Shea, Keiron and Nash, Ryan},
doi = {10.22214/ijraset.2022.47789},
eprint = {1511.08458},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/YOLO/Vorbemerkungen/An Introduction to Convolutional Neural Networks.pdf:pdf},
journal = {International Journal for Research in Applied Science and Engineering Technology},
keywords = {artificial neural networks,machine learn-,pattern recognition},
mendeley-groups = {BA Thesis},
number = {12},
pages = {943--947},
title = {{An Introduction to Convolutional Neural Networks}},
volume = {10},
year = {2022}
}

@article{Henderson2017,
abstract = {We present a method for training CNN-based object class detectors directly using mean average precision (mAP) as the training loss, in a truly end-to-end fashion that includes non-maximum suppresion (NMS) at training time. This contrasts with the traditional approach of training a CNN for a window classification loss, then applying NMS only at test time, when mAP is used as the evaluation metric in place of classification accuracy. However, mAP following NMS forms a piecewise-constant structured loss over thousands of windows, with gradients that do not convey useful information for gradient descent. Hence, we define new, general gradient-like quantities for piecewise constant functions, which have wide applicability. We describe how to calculate these efficiently for mAP following NMS, enabling to train a detector based on Fast R-CNN [1] directly for mAP. This model achieves equivalent performance to the standard Fast R-CNN on the PASCAL VOC 2007 and 2012 datasets, while being conceptually more appealing as the very same model and loss are used at both training and test time.},
archivePrefix = {arXiv},
arxivId = {1607.03476},
author = {Henderson, Paul and Ferrari, Vittorio},
doi = {10.1007/978-3-319-54193-8_13},
eprint = {1607.03476},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/YOLO/Vorbemerkungen/End-to-End Training of Object Class Detectors for mean Average Precision.pdf:pdf},
isbn = {9783319541921},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
mendeley-groups = {BA Thesis},
pages = {198--213},
title = {{End-to-end training of object class detectors for mean average precision}},
volume = {10115 LNCS},
year = {2017}
}


@article{Rezatofighi2019,
abstract = {Intersection over Union (IoU) is the most popular evaluation metric used in the object detection benchmarks. However, there is a gap between optimizing the commonly used distance losses for regressing the parameters of a bounding box and maximizing this metric value. The optimal objective for a metric is the metric itself. In the case of axis-aligned 2D bounding boxes, it can be shown that IoU can be directly used as a regression loss. However, IoU has a plateau making it infeasible to optimize in the case of non-overlapping bounding boxes. In this paper, we address the this weakness by introducing a generalized version of IoU as both a new loss and a new metric. By incorporating this generalized IoU ( GIoU) as a loss into the state-of-the art object detection frameworks, we show a consistent improvement on their performance using both the standard, IoU based, and new, GIoU based, performance measures on popular object detection benchmarks such as PASCAL VOC and MS COCO.},
archivePrefix = {arXiv},
arxivId = {1902.09630},
author = {Rezatofighi, Hamid and Tsoi, Nathan and Gwak, Junyoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
doi = {10.1109/CVPR.2019.00075},
eprint = {1902.09630},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/YOLO/Vorbemerkungen/Rezatofighi_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_CVPR_2019_paper.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Categorization,Deep Learning,Recognition: Detection,Retrieval},
mendeley-groups = {BA Thesis},
pages = {658--666},
title = {{Generalized intersection over union: A metric and a loss for bounding box regression}},
volume = {2019-June},
year = {2019}
}

@article{Terven2023,
abstract = {YOLO has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. We present a comprehensive analysis of YOLO's evolution, examining the innovations and contributions in each iteration from the original YOLO to YOLOv8. We start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. Finally, we summarize the essential lessons from YOLO's development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems.},
archivePrefix = {arXiv},
arxivId = {2304.00501},
author = {Terven, Juan and Cordova-Esparza, Diana},
eprint = {2304.00501},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/YOLO/A_Comprehensive_Review_of_YOLO_From_YOLOV1_and_Beyond.pdf:pdf},
keywords = {computer vision,deep learning,object detection,yolo},
mendeley-groups = {BA Thesis},
pages = {1--33},
title = {{A Comprehensive Review of YOLO: From YOLOv1 to YOLOv8 and Beyond}},
url = {http://arxiv.org/abs/2304.00501},
year = {2023}
}

@article{Zheng2020,
abstract = {Bounding box regression is the crucial step in object detection. In existing methods, while ℓn-norm loss is widely adopted for bounding box regression, it is not tailored to the evaluation metric, i.e., Intersection over Union (IoU). Recently, IoU loss and generalized IoU (GIoU) loss have been proposed to benefit the IoU metric, but still suffer from the problems of slow convergence and inaccurate regression. In this paper, we propose a Distance-IoU (DIoU) loss by incorporating the normalized distance between the predicted box and the target box, which converges much faster in training than IoU and GIoU losses. Furthermore, this paper summarizes three geometric factors in bounding box regression, i.e., overlap area, central point distance and aspect ratio, based on which a Complete IoU (CIoU) loss is proposed, thereby leading to faster convergence and better performance. By incorporating DIoU and CIoU losses into state-of-the-art object detection algorithms, e.g., YOLO v3, SSD and Faster R-CNN, we achieve notable performance gains in terms of not only IoU metric but also GIoU metric. Moreover, DIoU can be easily adopted into non-maximum suppression (NMS) to act as the criterion, further boosting performance improvement.},
archivePrefix = {arXiv},
arxivId = {1911.08287},
author = {Zheng, Zhaohui and Wang, Ping and Liu, Wei and Li, Jinze and Ye, Rongguang and Ren, Dongwei},
doi = {10.1609/aaai.v34i07.6999},
eprint = {1911.08287},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/YOLO/Distance-IoU Loss Faster and Better Learnign for Bounding Box Regression.pdf:pdf},
isbn = {9781577358350},
issn = {2159-5399},
journal = {AAAI 2020 - 34th AAAI Conference on Artificial Intelligence},
mendeley-groups = {BA Thesis},
number = {2},
pages = {12993--13000},
title = {{Distance-IoU loss: Faster and better learning for bounding box regression}},
year = {2020}
}
@article{Li2020,
abstract = {One-stage detector basically formulates object detection as dense classification and localization (i.e., bounding box regression). The classification is usually optimized by Focal Loss and the box location is commonly learned under Dirac delta distribution. A recent trend for one-stage detectors is to introduce an individual prediction branch to estimate the quality of localization, where the predicted quality facilitates the classification to improve detection performance. This paper delves into the representations of the above three fundamental elements: quality estimation, classification and localization. Two problems are discovered in existing practices, including (1) the inconsistent usage of the quality estimation and classification between training and inference, and (2) the inflexible Dirac delta distribution for localization. To address the problems, we design new representations for these elements. Specifically, we merge the quality estimation into the class prediction vector to form a joint representation, and use a vector to represent arbitrary distribution of box locations. The improved representations eliminate the inconsistency risk and accurately depict the flexible distribution in real data, but contain continuous labels, which is beyond the scope of Focal Loss. We then propose Generalized Focal Loss (GFL) that generalizes Focal Loss from its discrete form to the continuous version for successful optimization. On COCO test-dev, GFL achieves 45.0 Percent AP using ResNet-101 backbone, surpassing state-of-the-art SAPD (43.5 Percent) and ATSS (43.6 Percent) with higher or comparable inference speed.},
archivePrefix = {arXiv},
arxivId = {2006.04388},
author = {Li, Xiang and Wang, Wenhai and Wu, Lijun and Chen, Shuo and Hu, Xiaolin and Li, Jun and Tang, Jinhui and Yang, Jian},
eprint = {2006.04388},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/YOLO/Generalized Focal Loss Learning Qualified and Distributed Bounding Box for Dense Object Detection.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {BA Thesis},
pages = {1--14},
title = {{Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection}},
volume = {2020-December},
year = {2020}
}

@misc{Rossum2009,
author = {Rossum, Guido Van},
mendeley-groups = {Proposal/Small},
title = {{What's New In Python 3.0 — Python v3.0.1 documentation}},
url = {https://docs.python.org/3.0/whatsnew/3.0.html},
urldate = {2023-07-11},
year = {2009}
}

@article{Marowka2018,
abstract = {Python is gaining popularity in academia as the preferred language to teach novices serial programming. The syntax of Python is clean, easy, and simple to understand. At the same time, it is a high-level programming language that supports multi programming paradigms such as imperative, functional, and object-oriented. Therefore, by default, it is almost obvious to believe that Python is also the appropriate language for teaching parallel programming paradigms. This paper presents an in-depth study that examines to what extent Python language is suitable for teaching parallel programming to inexperienced students. The findings show that Python has stumbling blocks that prevent it from preserving its advantages when shifting from serial programming to parallel programming. Therefore, choosing Python as the first language for teaching parallel programming calls for strong justifications, especially when better solutions exist in the community.},
author = {Marowka, Ami},
doi = {10.1007/s10639-017-9607-0},
file = {:C\:/Users/timol/OneDrive - Universit{\"{a}}t M{\"{u}}nster/10. Fachsemester_SS_2023/BA Vorbereitung/Moratz_Thema/Literatur/03 Implementierung/Python + externe Bibliotheken/On parallel software engineering education using Python.pdf:pdf},
issn = {15737608},
journal = {Education and Information Technologies},
keywords = {Computer science education,Python,Teaching parallel programming},
mendeley-groups = {BA Thesis},
number = {1},
pages = {357--372},
publisher = {Education and Information Technologies},
title = {{On parallel software engineering education using python}},
volume = {23},
year = {2018}
}


@software{kelsey_jordahl_2020_3946761,
  author       = {Kelsey Jordahl and
                  Joris Van den Bossche and
                  Martin Fleischmann and
                  Jacob Wasserman and
                  James McBride and
                  Jeffrey Gerard and
                  Jeff Tratner and
                  Matthew Perry and
                  Adrian Garcia Badaracco and
                  Carson Farmer and
                  Geir Arne Hjelle and
                  Alan D. Snow and
                  Micah Cochran and
                  Sean Gillies and
                  Lucas Culbertson and
                  Matt Bartos and
                  Nick Eubank and
                  maxalbert and
                  Aleksey Bilogur and
                  Sergio Rey and
                  Christopher Ren and
                  Dani Arribas-Bel and
                  Leah Wasser and
                  Levi John Wolf and
                  Martin Journois and
                  Joshua Wilson and
                  Adam Greenhall and
                  Chris Holdgraf and
                  Filipe and
                  François Leblanc},
  title        = {geopandas/geopandas: v0.8.1},
  month        = jul,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {v0.8.1},
  doi          = {10.5281/zenodo.3946761},
  url          = {https://doi.org/10.5281/zenodo.3946761}
}


@software{reback2020pandas,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    url          = {https://doi.org/10.5281/zenodo.3509134}
}

@misc{numpy_main_web,
mendeley-groups = {BA Thesis},
title = {{NumPy}},
url = {https://numpy.org/},
urldate = {2023-07-11}
}
@misc{numpy_about,
mendeley-groups = {BA Thesis},
title = {{NumPy - About Us}},
url = {https://numpy.org/about/},
urldate = {2023-07-11}
}

@misc{opencv_about,
mendeley-groups = {BA Thesis},
title = {{About - OpenCV}},
url = {https://opencv.org/about/},
urldate = {2023-07-11}
}

@misc{opencv_release,
mendeley-groups = {BA Thesis},
title = {{Releases - OpenCV}},
url = {https://opencv.org/releases/},
urldate = {2023-07-11}
}


@misc{Canu_pysource,
author = {Canu, Sergio},
mendeley-groups = {BA Thesis},
title = {{Instance segmentation YOLO v8 | Opencv with Python tutorial - Pysource}},
url = {https://pysource.com/2023/02/21/instance-segmentation-yolo-v8-opencv-with-python-tutorial/},
urldate = {2023-07-11}
}

