%!TEX root = ../thesis.tex
\chapter{Implementierung (LISTINGS ÜBERPRÜFEN)} 
\label{ch:implementierung}


%\section{Implementierung in Python}
{\label{implementation_in_python}} 
Im Folgenden wird die Implementierung anhand von Codebeispielen erläutert. Die angegebenen Listings sind zum einfachen Verständnis gekürzt und ohne Kommentare. Für ein Listing des gesamten Codes mit Kommentaren siehe Anhang \ref{cd:gesamt_listing}. \\
EF Version ist die Abkürzung für \glqq Every Frame\grqq{} Version (1. YOLO Variante) und RV Version ist die Abkürzung für \glqq Result\grqq{} Version (2. YOLO Variante), die direkt mit einem von YOLO generierten Objekt arbeitet. 
\section{Main File}
{ \todo{main.py und shape\_sim\_meas Listings überprüfen!!!!}
	Das Main File importiert alle Unterskripte, da es auf die Funktionen zugreifen muss, um das Video zu verarbeiten und zu schreiben. Diese Unterskripte sind: 
	\begin{itemize}
		\item yolo\_every\_frame (siehe \ref{py:YOLO_every_frame})
		\item yolo\_result\_version (siehe \ref{py:YOLO_res_vers})
		\item DCE.py (siehe \ref{py:DCE})
		\item shape\_sim\_meas.py (siehe \ref{py:Shape_Sim_Meas})
	\end{itemize}
	Dazu wird die Erweiterung CV2 (siehe \ref{subsec:Computer_Vision_2}) eingelesen, um das Video aus einzelnen Frames zu generieren.\\
	Die Main Methode besteht aus einer Dictionary Variable \lstinline|options|, in der alle Einstellungen für die Verarbeitung des Videos gesetzt werden. Hier werden auch die einzelnen Zeitstempel gespeichert. Ein Ausschnitt ist in Listing \ref{cd:part_of_options_var} zu sehen. \\
	In diesem wird die Lese- und Schreibpfade für das Quell- und Ergebnisvideo festgelegt, sowie der Pfad für die Textdatei, die die Timestamps enthält. In den nächsten Zeilen kann festgelegt werden, auf bis viele Punkte die von YOLO detektierten Objekte reduziert werden. Diese werden in 4 unterschiedliche Objekttypen unterteilt: Auto (Car), Motorrad (Motorcycle), LKW (Truck) und andere Objekte (other\_Object). \\
	Des Weiteren wird das genutzte YOLO Modell definiert und festgelegt, ob nur die vereinfachten Umrisse der erkannten Objekte ausgegeben werden. Des Weiteren kann gesteuert werden, ob die von YOLO detektierten Objektboundingboxen schwarz ausgefüllt werden, sodass der Umriss klarer erkannt wird. Hier kann auch die Ausgabe der Labels gesteuert werden, diese beinhalten die Information, was für eine Klasse, bzw. Objekt, detektiert wurde und wie hoch der Confidence Score ist. \\
	Standardmäßig ist die Version des Codes ausgewählt, die das Video erst vollständig von YOLO analysieren lässt, dies lässt sich mit der \lstinline|yolo_every_frame| Boolean umstellen. Die letzte Boolean beschreibt, ob Zeitstempel gesetzt werden sollen. Dieses Dictionary hat noch weitere Einträge, die der Verwaltung der verschiedenen Zeitstempel und weiterer Messwerte dienen. \\
	\lstinputlisting[basicstyle=\ttfamily\scriptsize, linerange={338,339-342,344-346,348-351,353-357,359}, caption={Ausschnitt aus der \protect\lstinline|options| Variable in  Main.py}, label = {cd:part_of_options_var}]{../Code/main.py}
	Im weiteren Verlauf wird dann ausgewählte Version des Codes gestartet und beim Abschluss das Video und die Textdatei in die entsprechenden Pfade geschrieben.
	Es existieren außerdem Funktionen, um die Testfälle zur Evaluation mit einem Programmdurchlauf zu generieren und die \lstinline|options| Variable wieder auf ihre Standardwerte zurückzusetzen. Dies ist erforderlich um für Testfälle andere Einstellungen festlegen zu können.
}



\section{1. YOLO Variante (EF Version)} {
	\label{py:YOLO_every_frame}
	In dieser Variante wird das Video in einzelne Frames mit CV2 zerlegt, auf die dann jeweils der ausgewählte YOLO Algorithmus angewendet wird. Der Fortschrittsbalken bildet anhand der durchlaufenden Frames den Berechnungsfortschritt ab. 
	Es wird über alle Frames des Videos iteriert, in der das jeweilige Frame aus dem Video extrahiert wird und dann an die Methode übergeben wird, die YOLO anwendet. \todo{Linienbrechung Listings nachschauen}
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={41,43,45,46,48,50,56}, caption={Ausschnitt aus yolo\_every\_frame.py}, label = {cd:part_of_yolo_every_frame.py}]{../Code/YOLO/yolo_every_frame.py}
	Dies geschieht indem zuerst die Gesamtanzahl der Frames in der \lstinline|framecounter| Variablen gespeichert wird, welche den Iterator für die Schleife limitiert (siehe Listing \ref{cd:part_of_yolo_every_frame.py}). \\ 
	In der Schleife wird das jeweilige Frame an der \lstinline|i|-ten Stelle als Bilddatei in der \lstinline|img| Variablen gespeichert. Dieses wird dann im nächsten Schritt der Funktion übergeben, die das Bild mit YOLO analysiert und zurückgibt. Ein vorher festgelegtes Array speichert dann alle analysierten Bilder. \\ 
	Wenn die Schleife terminiert, wird das Array aus Bildern zu einem Video zusammengesetzt und gespeichert. \\

	
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={77,84,96,98,103,104,106,115,116,118,119,127-129,131,132}, caption={Ausschnitt aus der \protect\lstinline|run_yolo| Funktion in yolo\_every\_frame.py}, label = {cd:run_yolo_func_in_yolo_every_frame.py}]{../Code/YOLO/yolo_every_frame.py}
	
	Ausschnitte der \lstinline|run_yolo| Funktion sind in Listing \ref{cd:run_yolo_func_in_yolo_every_frame.py} zu sehen. Zuerst wird hier das YOLO Modell festgelegt. Danach wird der Frame von YOLO analysiert, welches in der yolo\_segmentation.py erfolgt. Hier wird ein Objekt zurückgeben, welches die Boundingboxen der detektierten Objekte, die jeweiligen Klassen, die segmentierten Umrisse und den jeweiligen Confidence Score enthält. \\
	Dieses Objekt wird in der darauffolgenden Schleife durchlaufen. Hier werden zunächst die Koordinaten der jeweiligen Boundingbox gesetzt und im nächsten Schritt werden die Umrisse mit der DCE vereinfacht (für eine genauere Beschreibung in der Theorie siehe Kap. \ref{sec:Discrete Curve Evolution} und im Code siehe Kap. \ref{py:DCE}). 
	Zuvor wird noch die Variable abgefragt, ob die Boundingboxen der erkannten Objekte mit schwarzen Pixeln gefüllt werden sollen. Mit CV2 werden danach die Boundingboxen und die Umrisse der Polygone gezeichnet. Für den Fall, dass die \lstinline|write_Labels| Variable im \lstinline|options| Dictionary auf True gesetzt ist, werden im nächsten Schritt der Confidence Score und die Class ID an die Boundingbox geschrieben. \\
	Zur Evaluation werden im nächsten Schritt die Winkelsummen für jedes Polygon summiert und in einem Array im  \lstinline|options| Dictionary gespeichert. \\
	Wenn alle Frames des Videos durchlaufen wurden, werden die einzelnen Frames wieder zu einem Video zusammengesetzt und statistische Auswertungen (siehe Kap. \ref{py:Shape_Sim_Meas}) durchgeführt. Damit ist dieser Abschnitt des Programmes abgeschlossen.

	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={31,37,46-48,59,61-64,68,70,72,73}, caption={Ausschnitt aus  yolo\_segementation.py}, label = {cd:yolo_in_yolo_segmentation.py}]{../Code/YOLO/yolo_segmentation.py}
	YOLO\_segmenation.py basiert auf einer Entwicklung von \citeauthor{Canu_pysource} \citep{Canu_pysource} und beinhaltet einige Abänderungen. Der Code auf den sich im Folgenden bezogen wird, ist in Listing \ref{cd:yolo_in_yolo_segmentation.py} zu sehen. Hier wird nach der Initialisierung des YOLO Modells die Detektionsfunktion ausgeführt. Diese beinhaltet die Prediction in Zeile 6 und eine IF Abfrage, wenn keine Objekte von YOLO erkannt wurden. Wenn Objekte erkannt wurden, werden deren Boundingboxen, ClassIDs, Umrisse und Confidence Scores zurückgeben. 
	}

\section{2. YOLO Variante (RV Version)}{
	\label{py:YOLO_res_vers}
	Diese Variante des Codes analysiert das Video direkt am Anfang mit YOLO. Dies bietet den Vorteil, dass durch die effiziente Implementierung von YOLO die Gesamtdauer des Programmes verringert wird. Der Fortschrittsbalken bildet bei dieser Implementierung anhand der von der DCE durchlaufenen Polygone den Berechnungsfortschritt ab.  Die Anwendung von YOLO findet direkt in main.py statt. Dies ist in Listing \ref{cd:yolo_result_main.py} zu sehen.
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={109,115,117,121,125,128,130}, caption={Ausschnitt aus \protect\lstinline|run_yolo_result_version| in main.py}, label = {cd:yolo_result_main.py}]{../Code/main.py}
	Da hier das gesamte Video in dem von YOLO generierten \lstinline|results| Objekt gespeichert wird, benötigt die Funktion, die das Video verändert nur dieses Objekt und das \lstinline|options| Dictionary. \\
	

	Die \lstinline|get_outline_for_every_object| Funktion (siehe Listing \ref{cd:yolo_result_get_outline_for_every_object.py}) läuft folgendermaßen ab. \\
	Die Schleife iteriert über die Gesamtanzahl der Frames im Video. Durch die IF Abfrage wird der Fall abgefangen, dass kein Objekt im Frame erkannt wurde. Wenn ein Objekt erkannt wurde, werden mit der \lstinline|get_data| Funktion die Daten der detektierten Objekte aus dem Frame exportiert. Ansonsten wird das Frame ohne Veränderung überschrieben, wenn das Video im \lstinline|options| Dictionary nicht auf schwarz gesetzt wurde. Die \lstinline|get_data| Funktion basiert auf \citeauthor{Canu_pysource} \citep{Canu_pysource} und ist ähnlich zu der in Kap. \ref{py:YOLO_every_frame} (s. Listing \ref{cd:yolo_in_yolo_segmentation.py}) aufgebaut. \\
	Diese Daten werden in einzelne Variablen abgespeichert. Danach wird auf die Umrisse die DCE (siehe Kap. \ref{py:DCE}) angewendet. Mit CV2 werden die vereinfachten Umrisse dann in das Frame gespeichert, indem das gerade analysierte Frame überschrieben wird. Im weiteren Verlauf wird dann das Frame, bzw. je nach Einstellung nur die Boundingboxen der detektierten Objekte, mit schwarzen Pixeln ausgefüllt. \\
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={31,38-40, 43-45,47-50,52-53,56,62,64-68}, caption={Ausschnitt 1 aus \protect\lstinline|get_outline_for_every_object| Funktion in yolo\_result\_version.py}, label = {cd:yolo_result_get_outline_for_every_object.py}]{../Code/YOLO/yolo_result_version.py}
	Die zweite FOR Schleife (siehe Listing \ref{cd:yolo_result_get_outline_for_every_object_second.py}) zeichnet für jedes erkannte Objekt im Frame die Boundingbox und die Labels, falls dies im \lstinline|options| Dictionary gesetzt wurde. Außerdem wird noch die Gesamtsumme der Winkel  zur späteren statistischen Auswertung für jedes Polygon berechnet.
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,firstnumber = 21,linerange={70,71,72,74,76,77,80,93,95,96,98,99,102}, caption={Ausschnitt 2 aus \protect\lstinline|get_outline_for_every_object| Funktion in yolo\_result\_version.py}, label = {cd:yolo_result_get_outline_for_every_object_second.py}]{../Code/YOLO/yolo_result_version.py}
	Wenn die Schleifen durchgelaufen sind, wird das veränderte \lstinline|result| Objekt und das \lstinline|options| Dictionary zurückgeben. Danach wird das Video an dem angegebenen Pfad gespeichert. Es werden statistische Auswertungen (siehe Kap. \ref{py:Shape_Sim_Meas}) durchgeführt und die Timestamps gespeichert. Damit ist dieser Teil des  Programmes abgeschlossen. \\
	}

\section{Discrete Curve Evolution}{
	\label{py:DCE}
	\todo{dce listings checken}
	Die folgende Implementierung basiert auf \citeauthor{Barkowsky2000} \citep{Barkowsky2000} (siehe Kap. \ref{sec:Discrete Curve Evolution}). Die DCE wird durch ähnlich implementierte Funktionen in beiden YOLO Implementierungen gestartet. Als Beispiel wird hier die Implementierung aus yolo\_result\_version.py genutzt. Diese ist in Listing \ref{cd:yolo_result_run_DCE.py} zu sehen. \\

	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={358-362,364,367-369,373,376}, caption={Ausschnitt aus \protect\lstinline|calc_k_for_all_points| Funktion in DCE.py}, label = {cd:DCE_calc_k_for_all_points.py}]{../Code/DCE/DCE.py}

	Hier wird anhand der erkannten Klassen Auto, Motorrad und LKW die Methode zur Polygonvereinfachung mit einer festen Punktgrenze ausgeführt. Dies passiert auch, falls das detektierte Objekt nicht zu diesen drei Klassen gehört. \\ 
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={107,116-126}, caption={Ausschnitt aus \protect\lstinline|run_DCE| Funktion in yolo\_result\_version.py}, label = {cd:yolo_result_run_DCE.py}]{../Code/YOLO/yolo_result_version.py}
	Zurückgegeben wird ein Array, welches die vereinfachten Umrisse von jedem Objekt enthält, da das Ursprungspolygon immer mit dem vereinfachten Polygon überschrieben wird. \todo{klare Benennung! entweder Umriss, oder Polygon}\\

	\subsection{Implementierung der K Wert Berechnung \label{impl:Calc_K_Val}} 

	Der K Wert wird in der folgenden Funktion \lstinline|calc_k_with_points| berechnet. Diese Methode basiert auf der Formel \ref{Equ_K_Bark} ( nach \citet{Latecki1999a})und ist dahingehend abgeändert worden, dass diese nicht mit Liniensegmenten, sondern mit drei Punkten berechnet werden kann. Die abgeänderte Formel lautet:
	\begin{equation}
		K(p,S_1,S_2) = \frac{\beta(p, S_1, S_2)l(p, S_1)l(p, S_2)}{l(p, S_1) + l(p, S_2)} 
		\label{equ_K_DCE_points}
	\end{equation}
	Im Programmcode ist dies folgendermaßen implementiert (siehe Listing \ref{cd:DCE_calc_k_with_points.py}). Als Eingabe wird das Polygon, der betrachtete Punkt (\lstinline|p|), der folgende (\lstinline|s1|) und der vorherige (\lstinline|s2|) Punkt erwartet. Die Reihenfolge von betrachteter, folgender und vorheriger Punkt bei der Parameterübergabe kann aufgrund von Sonderfallbehandlung in den Beschreibungen in Kap. \ref{impl:DCE_SimplyfierFunc} abweichen. \\ 
	Es wird zunächst der Winkel $\beta$ berechnet, indem alle drei Punkte und das Polygon übergeben werden. Danach werden die beiden Distanzen zwischen $p, S_1$ und $p, S_2$ berechnet. Die Winkelberechnungsfunktion arbeitet mit NumPy und die Distanzberechnungsfunktion basiert auf Funktionen, die GeoPandas bietet.
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={210,224-226,228,229}, caption={Ausschnitt aus \protect\lstinline|calc_k_with_points| Funktion in DCE.py}, label = {cd:DCE_calc_k_with_points.py}]{../Code/DCE/DCE.py}
	Diese drei Werte werden dann analog zur Formel \ref{equ_K_DCE_points} zum Wert K berechnet. Als letzten Schritt wird dieser Wert und der Winkel als Array zurückgegeben.
	
	In Listing \ref{cd:DCE_angle_and_distance.py} ist zu sehen, dass die Winkelberechnungsfunktion mit dem Arcustangens und $\pi$ arbeitet. Dies basiert auf der Dokumentation von NumPy \citep{numpy_angle}. Da die Berechnung ein Array ausgibt, müssen alle Elemente aufsummiert werden, um einen Wert zu erhalten. Dieser Wert wird dann in Radiant umgerechnet und zurückgeben. \\
	Die Distanzberechnung erfolgt mit einer Funktion, die GeoPandas bei \lstinline|Geopanda.Geoseries| Objekt bietet. Diese errechnet die Distanz zwischen den Punkten \lstinline|p1| und \lstinline|p2|. Danach wird diese zurückgegeben.

	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={332,344-346,356,357,359,360,364,381,390-393}, caption={Ausschnitte aus \protect\lstinline|get_angle_two_lines| und \protect\lstinline|get_distance_between_two_points| Funktionen in DCE.py}, label = {cd:DCE_angle_and_distance.py}]{../Code/DCE/DCE.py}

	\subsection{Implementierung der Vereinfachungsfunktion \label{impl:DCE_SimplyfierFunc}}

	

	Nun wird der Prozess innerhalb der DCE.py Datei genauer erläutert (siehe Listing \ref{cd:DCE_simplify_polygon_A1.py} - \ref{cd:DCE_simplify_polygon_A4.py}). Es ist zu beachten, dass die Berechnungsfunktion nur mit Indexen für die Punkte des Polygons arbeiten, sodass die Punkte nicht direkt angesteuert werden können. Da die DCE in dieser Arbeit mit GeoPandas (siehe Kap. \ref{subsec:Geopandas}) implementiert wurde, muss das Array zuerst in ein \lstinline|Geopandas.Geoseries| Objekt transformiert werden. \\
	Danach kann von diesem Polygon die Gesamtpunktanzahl berechnet werden und der Fall abgefangen werden, dass ein Polygon bereits weniger Punkte als die Punktanzahl, auf die das Polygon reduziert werden soll, hat. \\

	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={47,56-57,59-63}, caption={Ausschnitt 1 aus \protect\lstinline|simplify_polygon_fast_sec| Funktion in DCE.py}, label = {cd:DCE_simplify_polygon_A1.py}]{../Code/DCE/DCE.py}

	
	Es folgt die Berechnung der K Werte für alle Punkte, indem das Polygon einmal vollständig durchlaufen wird. Diese werden in einem zweidimensionalen Array gespeichert. Danach wird dieses Array in ein Numpy Array umgewandelt, damit die Funktionen der Bibliothek auf dieses angewendet werden können. Als nächsten Schritt wird dieses Array nach dem zweiten Index, dem K-Wert für jeden Punkt, sortiert, sodass der Index mit dem geringsten K-Wert an der ersten Stelle des Arrays steht. Hierzu wird das Quicksort-Verfahren (s. Kap. \ref{subsec:NumPy}), welches Numpy bereits integriert hat, genutzt. \\

	\lstinputlisting[firstnumber=9,basicstyle=\ttfamily\scriptsize, linerange={65,66,68,69,71,72,74,76}, caption={Ausschnitt 2 aus \protect\lstinline|simplify_polygon_fast_sec| Funktion in DCE.py}, label = {cd:DCE_simplify_polygon_A2.py}]{../Code/DCE/DCE.py}


	Im weiteren Verlauf folgt eine While Schleife (siehe Listing \ref{cd:DCE_simplify_polygon_A1.py}) in der zuerst der Index des Punktes mit dem geringsten K abgespeichert wird. Anhand dieses Indexes können nun die neuen K-Werte nach einer Entfernung dieses Punktes berechnet werden. Dieser Punkt wird nun im weiteren Verlauf aus dem Polygon entfernt, sodass im weiteren Verlauf die neuen K-Werte berechnet werden können. Es wird nun die neue verringerte Punktzahl des Polygons abgespeichert. \\
	Nun werden verschiedene Sonderfälle zur Berechnung erklärt. Der erste Sonderfall ist, dass \lstinline|indic| dem Wert 0 entspricht. Daraus kann der vorherige K-Wert \lstinline|k_bef| berechnet werden, indem als betrachteter Punkt der letzte Punkt des Polygons (Index: \lstinline|NoP_temp-1|) mit den Nachbarpunkten (als Index) \lstinline|0|  als folgender Punkt und \lstinline|NoP-2| als vorherigen Punkt der Berechungsfunktion übergeben wird. \\
	Bei der Berechnung des K-Wertes für den aktuellen Punkt \lstinline|k_act| muss als Parameter der erste Punkt des Polygons (Index: 0), der vorherige Punkt (\lstinline|NoP-1|) und \lstinline|1| als folgenden Punkt der Funktion \lstinline|calc_k_with_points| (s. Kap. \ref{impl:Calc_K_Val}) übergeben werden. \\
	Wenn \lstinline|indic| nicht dem Wert 0 entspricht, wird wie in Listing \ref{cd:DCE_simplify_polygon_A3.py} verfahren. Dieses Listing wird nun näher erläutert.
	Es wird zunächst der Fall behandelt, dass \lstinline|indic-1| dem Wert 0 entspricht. Wenn dies der Fall ist, muss Berechnung von \lstinline|k_bef| angepasst werden, indem als für die Übergabeparameter der K-Wert Berechnung, der erste Punkt des Polygons (\lstinline|0|), der folgende Punkt (\lstinline|1|) an zweiter Stelle und der letzte Punkt des Polygons (\lstinline|NoP-1|) an dritter Stelle übergeben werden. \\
	Im \lstinline|else| Teil dieser Abfrage werden weitere \lstinline|If| Abfragen genutzt um den Fall abzufangen, dass \lstinline|indic+1| größer ist als das Polygon Punkte hat, nachdem der Punkt mit dem geringsten K Wert entfernt wurde. In diesem Fall wird \lstinline|k_bef| so berechnet, dass der vorherige Punkt (\lstinline|indic-1|) von \lstinline|indic| mit den Übergabeparameter \lstinline|0| als folgenden und \lstinline|indic| als vorherigen Punkt berechnet wird. Wenn dies nicht der Fall ist, kann \lstinline|k_bef| auf dem vorgesehenen Weg mit den Übergabeparameter \lstinline|(indic-1, indic, indic-2)| berechnet werden. \\

	\lstinputlisting[firstnumber=17, basicstyle=\ttfamily\scriptsize, linerange={78,79,81,82,83,85,86,89,90,92,93}, caption={Ausschnitt 3 aus \protect\lstinline|simplify_polygon_fast_sec| Funktion in DCE.py}, label = {cd:DCE_simplify_polygon_A3.py}]{../Code/DCE/DCE.py}

	Nun wird der Sonderfall behandelt, dass \lstinline|indic+1| größer als die Anzahl der Punkte im Polygon nach dem Entfernen des Punktes mit dem geringsten K Wert ist, um \lstinline|k_act| zu berechnen. Diese Variable speichert den aktuellen neuen K-Wert des vorher entfernten Punktes. \\
	Wenn \lstinline|indic+1| größer ist, als die aktuelle Anzahl der Punkte im Polygon, muss die Berechnung dahingehend abgeändert werden, dass als aktueller betrachteter Punkt der K Berechnungsfunktion \lstinline|indic-1| übergeben wird, mit dem ersten Punkt (\lstinline|0|) des Polygons als ersten Nachbarn und dem vorherigen Punkt (\lstinline|indic-2|) als zweiten Nachbarn. Sollte \lstinline|indic+1| nicht größer als die aktuelle Anzahl der Punkte im Polygon sein, kann \lstinline|k_act| wie vorgesehenen berechnet werden mit den Parametern \lstinline|indic, indic-1, indic+1|.

	\lstinputlisting[firstnumber=28, basicstyle=\ttfamily\scriptsize, linerange={96,98,99,101}, caption={Ausschnitt 4 aus \protect\lstinline|simplify_polygon_fast_sec| Funktion in DCE.py}, label = {cd:DCE_simplify_polygon_A4.py}]{../Code/DCE/DCE.py}

	Wenn die Sonderfälle behandelt und \lstinline|k_bef| und \lstinline|k_act| berechnet wurden, können beide Werte im \lstinline|sort_arr| aktualisiert werden. Dazu existiert die Funktion \lstinline|update_sort_arr_sec|. Danach folgt eine Abfrage, ob das Polygon bereits auf die geforderte Anzahl Punkte vereinfacht worden ist. in diesem Fall wird das Polygon in Pixelwerte, bzw. ein Array, umgewandelt und zurückgeben. Ansonsten beginnt die Schleife von vorne. \\
	Außerhalb der Schleife ist die gleiche Rückgabefunktion \lstinline|polygon_to_pixels| vorhanden, um in jedem Fall ein vereinfachtes Polygon zurückzugeben.

	\todo{update Sort array muss noch beschrieben werden}

	
	
}


\section{Shape Similarity Measure}{
	\label{py:Shape_Sim_Meas}
	Beide Versionen der YOLO Implementierung erzeugen ein mehrdimensionales Array, welches für jedes Frame jedes Polygon mit Gesamtwinkelsumme, Class ID und Umriss enthält. Dieses mehrdimensionale Array wird ausgewertet, um einzuschätzen, ob die DCE zum Objekttracking geeignet ist. 

	Die Ergebnisse werden in einem weiteren Dictionary gespeichert, welches als letzten Schritt in eine Textdatei geschrieben wird, um alle Ergebnisse und Einstellungen zentral zu speichern. In Listing \ref{cd:SSM_main.py} ist zu sehen, in welcher Reihenfolge die Analysemethoden aufgerufen werden. 
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={4,11-17}, caption={Ausschnitt aus \protect\lstinline|calc_shape_similarity| Funktion in shape\_sim\_meas.py}, label = {cd:SSM_main.py}]{../Code/Shape_Similiarity/shape_sim_meas.py}
	Nachdem die Zeitstempel berechnet und im Results Dictionary gespeichert wurden, wird die erste Analysemethode aufgerufen. Dies geschieht im Detail folgendermaßen.

	Die folgende Methode \lstinline|calc_shape_similarity_compare_polygons| vergleicht die Winkelsummen jedes einzelnen Polygon mit dem ähnlichen Polygon im nächsten Frame. Dies geschieht, indem bei der Detektion der Objekte nach dem Vereinfachen mit DCE ein mehrdimensionales Array mit den Daten [Framenummer, Polygonnummer, Gesamtwinkelsumme (im Polygon), ClassID, [Umrisskoordinaten]] angelegt wird, welches dann zu einem weiteren Array hinzugefügt wird. Dadurch ist jedes Polygon in jedem Frame einzeln identifzier- und vergleichbar. 
	Die Auswertung dieses mehrdimensionalen Arrays erfolgt ähnlich zu Listing \ref{cd:shape_sim_meas_compare_poly.py}.\\

	Die Schleife iteriert über alle Frames. Innerhalb dieser wird abgefragt, ob im nächsten Frame mehr Objekte detektiert wurden, als im betrachteten Frame. Dies ist wichtig, damit die nächste Schleife nur über so viele Polygone iteriert, wie das Frame mit der geringeren Anzahl hat. Wenn das nächste Frame jedoch weniger Polygone als das betrachtete Frame hat, dürfen nur so viele Polygone betrachtet werden, wie im nächsten Frame vorhanden sind. \\
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={22,30,31,33-36,38-44}, caption={Ausschnitt 1 aus \protect\lstinline|calc_shape_similarity_compare_polygons| Funktion in sha\-pe\_sim\_me\-as.py}, label = {cd:shape_sim_meas_compare_poly.py}]{../Code/Shape_Similiarity/shape_sim_meas.py}
	Die integrierte FOR Schleife (siehe Listing \ref{cd:shape_sim_meas_compare_poly_second.py}) vergleicht die Winkelsummen der einzelnen Polygone. Dies wird dadurch ermöglicht, dass die temporäre Variable (\lstinline|temp|) nur dann berechnet wird, wenn das Polygon im betracheten Frame an der gleichen Stelle im Array steht, wie das Polygon im nächsten Frame. 
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,firstnumber=15, linerange={45-51}, caption={Ausschnitt 2 aus \protect\lstinline|calc_shape_similarity_compare_polygons| Funktion in sha\-pe\_sim\_me\-as.py}, label = {cd:shape_sim_meas_compare_poly_second.py}]{../Code/Shape_Similiarity/shape_sim_meas.py}
	Diese temporäre Variable muss immer positiv sein, was durch die IF Abfrage sichergestellt ist, da dies sonst die Differenzvariable verfälscht. Danach wird die Differenzvariable mit der temporären Variable addiert. Es wird nun die Gesamtanzahl der Punkte berechnet, welche identisch mit der Anzahl der berechneten Winkel ist. Zuletzt wird diese mit der Differenzvariable im \lstinline|options| Dictionary gespeichert. 
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,firstnumber=22, linerange={53,54,56-59,61-63}, caption={Ausschnitt 3 aus \protect\lstinline|calc_shape_similarity_compare_polygons| Funktion in sha\-pe\_sim\_me\-as.py}, label = {cd:shape_sim_meas_compare_poly_third.py}]{../Code/Shape_Similiarity/shape_sim_meas.py} 
	Die statistischen Auswertungen, werden alle im Dictionary (siehe Listing \ref{cd:shape_sim_meas_compare_poly_third.py}) in Radiant und Degree gespeichert. Hier wird  die Winkeldifferenz über alle Frames und Polygone, die durchschnittliche Winkelabweichung der pro Polygon und pro Winkel in das Dictionary geschrieben. Außerdem wird noch die Gesamtanzahl der erkannten Punkte gespeichert, die der Anzahl der Winkel entspricht, da zu jedem Punkt in den Polygonen ein Winkel berechnet wurde. \\
	
	Danach wird die Winkelabweichung mit der Methode in Listing \ref{cd:shape_sim_meas_one_frame_first.py} berechnet, welche alle Polygone der gleichen Klasse in einem Frame miteinander vergleicht. Der Messwert wird dadurch berechnet, dass über alle Frames iteriert wird.
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={70,92,93,95,96,98,99,101,102,104}, caption={Ausschnitt aus \protect\lstinline|calc_shape_sim_compare_classes_in_one_frame| Funktion in sha\-pe\_sim\_me\-as.py}, label = {cd:shape_sim_meas_one_frame_first.py}]{../Code/Shape_Similiarity/shape_sim_meas.py} 
	Die Methode \lstinline|compare_polygons_in_frame| gibt ein Array zurück, welches die aufsummierten Abweichungen enthält. Dies geschieht indem mit der \lstinline|get_inidzes_and_classes| Methode die Winkelsumme des ersten Polygons jeder Klasse extrahiert wird und in der nächsten Methode \linebreak \lstinline|calc_measures_in_one_frame| diese mit allen anderen Polygonen der gleichen Klasse im Frame verglichen wird. Das Array mit den extrahierten Winkelsummen jeder Klasse wird im folgenden als Referenzklasse bezeichnet.\\
	Das Vergleichen geschieht indem, wie in Listing \ref{cd:shape_sim_meas_calc_SSM_one_frame_first.py} als Beispielausschnitt zu sehen, indem über alle Polygone im Frame iteriert wird. Wenn die ClassID, in diesem Fall 2 für Car, mit der des Polygons im Frame übereinstimmt, kann die Differenzvariable berechnet werden. 
	\lstinputlisting[basicstyle=\ttfamily\scriptsize,linerange={235,236,247-254}, caption={Ausschnitt 1 aus \protect\lstinline|calc_measure_in_one_frame| Funktion in sha\-pe\_sim\_me\-as.py}, label = {cd:shape_sim_meas_calc_SSM_one_frame_first.py}]{../Code/Shape_Similiarity/shape_sim_meas.py} Diese wird in einem Array gespeichert, welches am Ende zurückgeben wird. Analog geschieht dies für die Klassen Truck und Motorcycle. Wenn keine dieser Klassen erkannt wurde, wird folgende Ausnahme behandelt (siehe Listing \ref{cd:shape_sim_meas_calc_SSM_one_frame_second.py}). 
	\lstinputlisting[ basicstyle=\ttfamily\scriptsize, firstnumber=11, linerange={267-275}, caption={Ausschnitt 2 aus \protect\lstinline|calc_measure_in_one_frame| Funktion in sha\-pe\_sim\_me\-as.py}, label = {cd:shape_sim_meas_calc_SSM_one_frame_second.py}]{../Code/Shape_Similiarity/shape_sim_meas.py} 
	Aus dem Array mit den Referenzvariablen wird, falls vorhanden, die Winkelsumme abgerufen. Wenn diese Winkelsumme nicht vorhanden ist, wird dem Array der Differenzvariable 0 addiert um diese nicht zu ändern. Sonst wird analog zum obigen Verfahren der Messwert berechnet, nur mit der Änderung das die ClassID zu jedem Wert gespeichert wird, um die Vergleichbarkeit zu gewährleisten. \\
	Damit ist das Erstellen der Arrays und die Schleife in Listing \ref{cd:shape_sim_meas_calc_SSM_one_frame_first.py} abgeschlossen. Diese Arrays werden aufsummiert. Bei Objekten, welche nicht den drei Hauptklassen entsprachen, wird mit einer Methode, welche die berechneten Werte in einzelne Arrays für jede detektierte Klasse sortiert (ähnlich zu Bucketsort), die Winkelabweichung berechnet. Für eine nähere Beschreibung siehe Anhang \ref{cd:listing_shape_sim_meas.py} ab Zeile 125. \todo{genauer beschreiben?} Eine Berechnung ist falsch, wenn nur ein Element einer Klasse pro Frame detektiert wurde, da die Winkeldifferenz dann immer 0 beträgt. Falls dies der Fall ist, wird dies im Results Dictionary für die jeweilige Klasse mitgeteilt.
	Wenn alle Werte in das Result Dictionary geschrieben wurden, wird dieses als Textdatei abgespeichert und das Programm ist vollständig abgeschlossen.

}







