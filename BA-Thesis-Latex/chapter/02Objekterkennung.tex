%!TEX root = ../thesis.tex
\chapter{Objekterkennung mit neuronalen Netzen}
\label{ch:Theoretischer Hintergrund}

\todo{Eingangstext überarbeiten}
\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.415\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/yolo_comp/yolo_acc_perf.png}
		\caption{Genauigkeitsperformance verschiedener Objektdetektoren in verschiedenen Iterationen \cite{Pavani2022}}
		\label{Scr:comp_object_detectorAcc}
	\end{subfigure}
    \hfill
	\begin{subfigure}[b]{0.45\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/yolo_comp/yolo_prec_perf.png}
		\caption{Präzisionsperformance verschiedener Objektdetektoren in verschiedenen Iterationen  \cite{Pavani2022}}
		\label{Scr:comp_object_detectorPrec}
	\end{subfigure} 
	\caption[Vergleich von verschiedenen Objektdetektionsalgorithmen]{Vergleich von verschiedenen Objektdetektionsalgorithmen; die Werte von YOLO sind relativ konstant über alle 10 Iterationen \cite{Pavani2022}}
	\label{Scr:comp_object_detector}
\end{figure}
\todo{Kapitel mit Vergleich von verschiedenne objektdetektoren anfügen}
{Im Folgenden wird sich hauptsächlich auf Objektdetektion auf Bildern bezogen, weil Videos aus einzelnen schnell aufeinander folgenden Bildern (bzw. Frames) bestehen. \\
Zur Objekterkennung auf Bildern gibt es verschiedene Ansätze. Es gibt ressourcenschonende Ansätze, wie die Schwellwertsegmentierung nach \citeauthor{Otsu1979} \cite{Otsu1979}. Dieses Segmentierungsverfahren ist zwar sehr schnell, nimmt aber keine Klassifikation der segmentierten Objekte vor, wodurch eine Nutzung im Rahmen dieser Arbeit als nicht sinnvoll erachtet wird. \\
Maschinelles Lernen kann die Herausforderung der gleichzeitigen Objektdetektion mit entsprechender Klassifizierung lösen. Hierzu gibt es verschiedene Algorithmen, wie CNN (\glqq Convolutional Neural Network\grqq{}), KNN (\glqq k-nearest neighbors\grqq{} Algorithmus), den Haarcascade Algorithmus oder \glqq You Only Look Once\grqq{} (YOLO) 
\cite{Pavani2022}. \\
Von \citeauthor{Pavani2022} \cite{Pavani2022} wurde ein Vergleich dieser Algorithmen in einem  Verkehrsflussdetektionszenario vorgestellt \citep{Pavani2022}. Die hier vorgestellten Herausforderung, dass Verkehr immer heterogener wird, ähnelt dieser Arbeit, da Verkehrstracking von Genauigkeit und Performance der verwendeten Algorithmen abhängt.\\
Wenn man die Präzision (s. \ref{Scr:comp_object_detectorAcc}) und Genauigkeit (s. \ref{Scr:comp_object_detectorPrec}) von den verschiedenen Algorithmen vergleicht, ist zu erkennen, dass YOLO die beste Performance bei Klassifikation, die beste mittlere Genauigkeit und Präzision besitzt (s. \ref{scr:comp_obj_det_mean_av}, \pageref{scr:comp_obj_det_mean_av}). Dies liegt an der neuartigen Implementierung von YOLO. Der KNN Algorithmus ist sehr ineffizient aufgrund der Anzahl der Berechnungsschritte.\\
Aus diesen Gründen wird der YOLO Algorithmus in dieser Arbeit verwendet und im Folgenden genauer erläutert.

 }


%\section{\glqq You Only Look Once\grqq{}(YOLO)}
{ 
	
	\section{Der YOLO Algorithmus \label{subsec:YOLO_Alg}} 
	{Da der Blick des Menschen Objekterkennung, -einordnung und -wirkung intuitiv ermöglicht, ist es unserem Gehirn im Zusammenspiel mit unseren Augen möglich, schnell und genau zu sehen. Durch diese Fähigkeiten können wir mit nur wenig bewussten Gedanken komplexe Aufgaben, wie Fahrradfahren bewältigen, bei denen gleichzeitig mehrere Sinne beansprucht werden. \citep{Redmon2016}. \\
	Dem Computer kann dies mit schnellen und genauen Algorithmen zur Objekterkennung beigebracht werden. Aktuelle Systeme nutzen Klassifikatoren zur Objekterkennung. Dieser wird an verschiedenen Stellen in variablen Skalierungen im Testbild angewendet, um eine Klassifizierung eines Objektes zu ermöglichen \citep{Redmon2016}. \\ 
	
	\begin{figure}[ht]
		\centering
		\includegraphics*[scale = 1, keepaspectratio, trim=2 2 2 2 ]{images/YOLO/YOLO_detection_system.png}
		\caption[Das YOLO Objekterkennungsystem]{Das YOLO Objekterkennungsystem \citep{Redmon2016}}
		\label{YOLO_Objectdetection}
 	\end{figure}\glqq You Only Look Once\grqq{} (YOLO) betrachtet Objekterkennung als einzelnes Regressionsproblem, indem direkt von Bildpixel zu Boundingbox Koordinaten und Klassenwahrscheinlichkeiten berechnet wird. Dieser Algorithmus analysiert nur einmal ein Bild und sagt direkt vorher, welche Objekte wo vorhanden sind. Dadurch ist die Komplexität des  Aufbaus von YOLO sehr gering, wie in Abb. \ref{YOLO_Objectdetection} zu sehen \citep{Redmon2016}. \\
	Die Performance zur Objekterkennung wird durch das Training von YOLO mit vollständigen Bildern gesteigert. Durch dieses vereinheitlichte Modell entstehen mehrere Vorteile gegenüber den traditionellen Objekterkennungssystemen \citep{Redmon2016}. \\
	Der erste Vorteil von YOLO ist die gesteigerte Performance. Dies wird dadurch ermöglicht, dass Objekterkennung auf Bildern als Regressionproblem betrachtet wird und deshalb keine komplexe Pipeline die Verarbeitung eines Bildes verlangsamt.  \citep{Redmon2016}. 
	Zweitens analysiert YOLO ein Bild global mit Vorhersagen zur Objekterkennung. Dadurch kann YOLO beim Verwechseln von Hintergrund und Objekten im Vordergrund um die Hälfte im Vergleich zu Fast R-CNN verringern. Dies geschieht vor allem durch den größeren Kontext, den YOLO durch die Gesamtbildanalyse gewinnt \citep{Redmon2016}. \\
	Der dritte Vorteil ist das YOLO mit generalisierten Repräsentationen von Objekten trainiert wurde um die Fehlertoleranz bei der Anwendung auf neue Bereiche und unerwartete Eingaben zu vergrößern, aufgrund der Möglichkeit der hohen Verallgemeinerung \citep{Redmon2016}. \\
	Ein Nachteil von YOLO liegt in der Genauigkeit. Der Algorithmus hat Schwierigkeiten einige, insbesondere kleine, Objekte genau zu lokalisieren \citep{Redmon2016}. \\
	Da der Quellcode, mehrere vortrainierte Modelle und die Trainingsdaten von YOLO Open Source sind und zum Download bereitstehen, ist dieser Algorithmus für den Rahmen dieser Arbeit leicht zugänglich und anwendbar \citep{Redmon2016}. \\

	YOLO unterteilt in Bild in $S \times S $ Rasterzellen. Wenn der Mittelpunkt eines Objektes in eine Rasterzelle fällt, ist diese für die Erkennung des Objektes zuständig. Boundingboxen und ihre jeweiligen Confidence Scores werden für jede Rasterzelle vorhergesagt \citep{Redmon2016}.
	Der Confidence Score beschreibt, wie sicher sich das Modell ist, dass die Boundingbox ein Objekt dieser Klasse enthält und für wie genau das Modell diese Vorhersage hält. \\
	Dieser hier berechnete Wert enthält nicht nur die Wahrscheinlichkeit, dass diese Klasse in der Bounding Box vorkommt, sondern auch wie gut die vorhergesagte Box mit dem detektierten Objekt überein stimmt. Ein Beispielablauf ist in Abb. \ref{YOLO_Model} zu sehen.
	\begin{figure}[ht]
		\centering
		\includegraphics*[scale = 2, keepaspectratio, trim=2 2 2 2 ]{images/YOLO/YOLO_model.png}
		\caption[Das YOLO Modell]{Das YOLO Modell\citep{Redmon2016}}
		\label{YOLO_Model}
 	\end{figure}

	


	Da jede Rasterzelle nur 2 Bounding Boxen vorhersagen und eine Klasse haben kann, unterliegt YOLO einer räumlichen Einschränkung. Dies begrenzt die Anzahl der benachbarten Objekte, die das Modell vorhersagen kann. Außerdem ist es für das Modell schwierig, kleine Objekte, die in Gruppen auftreten zu detektieren \citep{Redmon2016}. \\
	Eine weitere Herausforderung ist, dass Objekte mit neuen oder ungewöhnlichen Formen auftreten können und dadurch die Vorhersage erschwert wird. Da die Netzwerkarchitektur aus mehreren 'Downsampling' Schichten besteht, benutzt das Modell relativ grobe Features zur Vorhersage der Bounding Boxen \citep{Redmon2016}. \\
	Außerdem sorgt das Training mit einer Verlustfunktion (für eine Erklärung s.  Formel \ref{YOLO_Loss_function}, S. \pageref{YOLO_Loss_function} und Abb.  \ref{YOLO_loss_function_detail}, S. \pageref{YOLO_loss_function_detail}), die die Erkennungsleistung annähert, dafür dass Fehler bei kleinen Bounding Boxen genauso wie bei großen Bounding Boxen behandelt werden. Dies ist ein Nachteil, weil ein kleiner Fehler in einer großen Box meistens wenig Auswirkungen hat, aber ein kleiner Fehler in einer kleinen Box eine sehr viel größer Auswirkung auf die IOU hat. Falsche Lokalisierungen sind eine weitere Hauptfehlerquelle \citep{Redmon2016}. \\
	YOLO ist für den Anwendungszweck dieser Arbeit geeignet, weil der Algorithmus die entsprechende Performance und einfache Verfügbarkeit von trainierten Modellen bietet. Außerdem existieren mehrere weitere Versionen (s. Abb. \ref{YOLO_timeline_vers}, S. \pageref{YOLO_timeline_vers}) von YOLO, die Vorteile in einzelnen Aspekten bieten \citep{Terven2023}. Zuvor war angedacht eine Schwellwertsegmentierung, bspw. nach \citeauthor{Otsu1979} \citep{Otsu1979}, zur Objektdetektion zu verwenden, da diese Methode ressourcenschonender ist. Dieser Ansatz wurde jedoch verworfen, weil die Implementierung den Rahmen dieser Arbeit übersteigen würde.\\

	Im Rahmen dieser Arbeit wird YOLOv8 von Ultralytics verwendet. Diese bietet Vorteile in der Performance und Genauigkeit der Objektdetektierung. 
	} 

	\section{YOLOv8 von Ultralytics}{ \label{subsec:YOLOv8_theoretic}
	
	Im Januar 2023 wurde von der Firma Ultralytics YOLOv8 veröffentlicht, welches auf YOLOv5 basiert. Diese Version beinhaltet 5 verschiedene Modelle (YOLOv8n (nano), YOLOv8s (small), YOLOv8m (medium), YOLOv8l (large), YOLOv8x (extra large)), die mit unterschiedlich großen Datensätzen trainiert wurden  \citep{Terven2023}. \\	
	Ein Vorteil dieser YOLO Implementierung ist, dass verschiedene Varianten für Objektdetektion, -segmentierung und -verfolgung, sowie -klassifizierung existieren. In dieser Arbeit wird hauptsächlich die \glqq -seg\grqq{}-Variante verwendet, welches bereits eine Segmentierung der Umrisse der detektierten Objekte integriert hat.
	\begin{figure}[h]
		\centering
		\includegraphics*[scale = 0.20, keepaspectratio]{images/YOLO/YOLOv8_object_detector_general.png}
		\caption[Architektur modernen Objektdetektoren]{Architektur modernen Objektdetektoren \citep{Terven2023}}
		\label{YOLO_obj_det_gen}
	\end{figure}
	Die Architektur dieser Algorithmen kann man in 3 Teile aufteilen (s. Abb. \ref{YOLO_obj_det_gen}). Dies sind der Backbone, der Neck und der Head \citep{Terven2023}. \\
	Das Detektieren nützlicher Features vom Eingabebild geschieht im Backbone, welcher meist als CNN implementiert ist \citep{Terven2023}. \\
	Zwischen Backbone und Head wird der Neck eingesetzt, um die Features, die der Backbone ausgibt, zu aggregieren und zu verfeinern. Der Fokus liegt auf der Verbesserung der räumlichen und semantischen Informationen über die unterschiedlichen Skalierungen hinweg \citep{Terven2023}. \\
	Die letzte Komponente ist der Head, welcher die Vorhersagen, aufgrund der von dem Backbone und Neck gelieferten Features, trifft. Hier werden meistens aufgabenspezifische Teilnetze eingesetzt, um Klassifizierung, Lokalisierung und auch sofortige Segmentierung durchzuführen. Aus den Features, die der Neck liefert, erstellt der Head Vorhersagen für jeden Objektkandidaten. Ein Post-Procressing Schritt, wie die Non-Maximum-Supression (NMS), filtert überlappende Vorhersagen heraus, sodass nur die sichersten Detektionen genutzt werden \citep{Terven2023}.\\
	Da YOLOv8 auf YOLOv5 basiert, wird in diesem ein ähnlicher Backbone genutzt. Für die Architektur von YOLOv8 s. Abb. \ref{YOLOv8_Arch} (S. \pageref{YOLOv8_Arch}). 

	Um die Performance insbesondere bei der Objekterkennung von kleineren Objekten zu verbessern, nutzt YOLOv8 CloU \citep{Zheng2020} und DFL \citep{Li2020} Verlustfunktionen für Boundingboxloss und binäre Kreuzentropie für Klassifizierungsloss \citep{Terven2023}. \\

	Mit dem YOLOv8-Seg Modell wird auch eine Variante angeboten, die semantische Segmentierung ermöglicht. Dieses Modell wird in dieser Arbeit genutzt, da es den Anforderungen entspricht.
	}
}
